# MMAsia24-XMSMO
This repository provides the implementation of the SITransformer model, as described in the [paper](https://arxiv.org/abs/2408.15829). The SITransformer model addresses the challenge of extreme multimodal summarization, combining information from multiple modalities (document and video) to generate high-quality summaries. The model leverages shared information across modalities to effectively reduce the impact of  irrelevant details and noise in multimodal data and therefore improve the summarization quality.

## Data

You can access the multimodal datasets used for training and evaluation through the following link:

[Download Dataset](https://drive.google.com/drive/folders/1jDs-uyZL8y70iZuC08IeROyXrfoUMgmU?usp=drive_link)

Please create a folder called `data` and put all data inside.

## Code

All code is stored in the this folder. To run the project, follow these steps:

1. **Run the main script**: The entry point to the code is the `run.ipynb` file. This file will guide you through the process of running the model on your multimodal data.

2. **Evaluate the performance**: After running the model, you can evaluate its performance by running the `eval.ipynb` file. During the evaluation process, make sure to store the test data and model-generated outputs in two separate folders inside this folder. For example, you can place the ground truth data in the `test` folder and the model-generated outputs in the `model_generated` folder which are both inside this folder.

There are two primary types of scripts:

- **Model scripts** (e.g., `my_model_noise_filter.py`): These scripts implement different kinds of models. In the case of SITransformer, these scripts contain the architecture of the multimodal summarization model.
- **Training scripts** (e.g., `my_train_noise_filter.py`): These scripts are used to train the corresponding model. Generally, you only need to run the training script to get the final results, which include the trained model and the generated outputs.

During both the training and evaluation processes, the model-generated results will be stored in the `output` folder.

## Citation


If you use this model or its results in your research, please cite the following paper:
```bibtex
@article{liu2024sitransformer,
  title={SITransformer: Shared Information-Guided Transformer for Extreme Multimodal Summarization},
  author={Liu, Sicheng and Wang, Lintao and Zhu, Xiaogan and Lu, Xuequan and Wang, Zhiyong and Hu, Kun},
  journal={arXiv preprint arXiv:2408.15829},
  year={2024}
}
```

<!-- ## Code
All code is stored in the code folder. To run the code, run the 'run.ipynb' file. To evaluate the performance, run the 'eval.ipynb' file. During the evaluation process, the test data and the data generated by the model should be stored in two folders within the 'code' folder. (For example, you can put it in the 'test'and 'model_generated' folders)

There are two main files. On is model (e.g. my_model_noise_filter.py). These file are used to implement different kinds of models. The other is train (e.g. my_train_noise_filter.py). These file are used to train the corresponding model. Generally, we only need to run the train file to get final result.

During training, the model generated results will be stored in output folder (for both training and testing stages).

## Data
You are free to access the data through the [link](https://drive.google.com/drive/folders/1jDs-uyZL8y70iZuC08IeROyXrfoUMgmU?usp=drive_link) -->
